{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7B-EIie4I0-",
    "outputId": "052f9ed6-2667-4a8a-b6f5-2a8f4805f9a4"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U kaggle_environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pJYIaVlk4MFv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termcolor not installed, skipping dependency\n",
      "No pygame installed, ignoring import\n",
      "Loading environment lux_ai_s3 failed: No module named 'chex'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from kaggle_environments import make, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHSeYzUy4OiC",
    "outputId": "bb79c8c8-e94a-48e0-9291-f03617da2f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing rock_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rock_agent.py\n",
    "\n",
    "#Example of the simple agent\n",
    "#0 - rock\n",
    "#1 - paper\n",
    "#2 - scissors\n",
    "def your_agent(observation, configuration):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnrR2kf2cw7H",
    "outputId": "6a41a43a-ad6d-4d68-d322-08d659656f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing paper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile paper.py\n",
    "\n",
    "#strategy with only papers\n",
    "def paper(observation, configuration):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkX1o-uMc3kb",
    "outputId": "7437c5d4-97bd-4128-ac27-667e9d0a3eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scissors.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scissors.py\n",
    "\n",
    "# strategy with only scissors\n",
    "def scissors(observation, configuration):\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ts2auBSW4RMg",
    "outputId": "7468f380-8a3c-451e-d31d-1ab07cf3bdb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing copy_opponent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile copy_opponent.py\n",
    "\n",
    "import random  # Добавляем импорт random\n",
    "\n",
    "def copy_opponent(observation, configuration):\n",
    "    # Если у нас есть информация о последнем ходе противника\n",
    "    if observation.step > 0:\n",
    "        return observation.lastOpponentAction\n",
    "    # Начальный шаг\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aj54d7xK4_9C",
    "outputId": "c0cfb466-88fe-4fa7-cb9e-37c672b20806"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    \"rps\", #environment to use - no need to change\n",
    "    [\"rock_agent.py\", \"copy_opponent.py\"], #agents to evaluate\n",
    "    configuration={\"episodeSteps\": 100} #number of episodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N18l8qRg4Zls",
    "outputId": "ce543c8f-9075-4bd9-f928-25f0760ff4f1"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evaluate(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#environment to use - no need to change\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrock_agent.py\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneural_network.py\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;66;03m#agents to evaluate\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     configuration\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisodeSteps\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m100\u001b[39m} \u001b[38;5;66;03m#number of episodes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m )\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\kaggle_environments\\core.py:72\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(environment, agents, configuration, steps, num_episodes, debug, state)\u001b[0m\n\u001b[0;32m     70\u001b[0m rewards \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_episodes)]\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_episodes):\n\u001b[1;32m---> 72\u001b[0m     last_state \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mrun(agents)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     73\u001b[0m     rewards[i] \u001b[38;5;241m=\u001b[39m [state\u001b[38;5;241m.\u001b[39mreward \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m last_state]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rewards\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\kaggle_environments\\core.py:264\u001b[0m, in \u001b[0;36mEnvironment.run\u001b[1;34m(self, agents)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(agents):\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidArgument(\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m agents were expected, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(agents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was given.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 264\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__agent_runner(agents)\n\u001b[0;32m    265\u001b[0m start \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;129;01mand\u001b[39;00m perf_counter() \u001b[38;5;241m-\u001b[39m start \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfiguration\u001b[38;5;241m.\u001b[39mrunTimeout:\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\kaggle_environments\\core.py:671\u001b[0m, in \u001b[0;36mEnvironment.__agent_runner\u001b[1;34m(self, agents)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__agent_runner\u001b[39m(\u001b[38;5;28mself\u001b[39m, agents):\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;66;03m# Generate the agents.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m     agents \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 671\u001b[0m         Agent(agent, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    672\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m agent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    673\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    674\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m agents\n\u001b[0;32m    675\u001b[0m     ]\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mact\u001b[39m(none_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agents) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate):\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\kaggle_environments\\agent.py:143\u001b[0m, in \u001b[0;36mAgent.__init__\u001b[1;34m(self, raw, environment)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment_name \u001b[38;5;241m=\u001b[39m environment\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw \u001b[38;5;241m=\u001b[39m raw\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_parallelizable \u001b[38;5;241m=\u001b[39m build_agent(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_agents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment_name)\n",
      "File \u001b[1;32mF:\\anaconda\\Lib\\site-packages\\kaggle_environments\\agent.py:116\u001b[0m, in \u001b[0;36mbuild_agent\u001b[1;34m(raw, builtin_agents, environment_name)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(raw):\n\u001b[0;32m    115\u001b[0m     raw_agent \u001b[38;5;241m=\u001b[39m read_file(raw, raw)\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(raw) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m raw \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m raw)) \u001b[38;5;129;01mor\u001b[39;00m raw \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m20\u001b[39m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find : \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m raw)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Attempt to execute the last callable or just return the string.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    \"rps\", #environment to use - no need to change\n",
    "    [\"rock_agent.py\", \"neural_network.py\"], #agents to evaluate\n",
    "    configuration={\"episodeSteps\": 100} #number of episodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iU1VDV4toNSA",
    "outputId": "ce9da0ec-d11a-4d7f-f97e-e5d67617df1a"
   },
   "outputs": [],
   "source": [
    "%%writefile keep_strategy.py\n",
    "import random\n",
    "import math\n",
    "\n",
    "my_action = []\n",
    "\n",
    "def keep_strategy(observation, configuration):\n",
    "    def get_score(left_move, right_move):\n",
    "        # This method exists in this file so it can be consumed from rps.py and agents.py without a circular dependency\n",
    "        delta = (\n",
    "            right_move - left_move\n",
    "            if (left_move + right_move) % 2 == 0\n",
    "            else left_move - right_move\n",
    "        )\n",
    "        return 0 if delta == 0 else math.copysign(1, delta)\n",
    "    global my_action\n",
    "    if observation.step == 0:\n",
    "        answer = random.randrange(0, configuration.signs)\n",
    "        my_action.append(answer)\n",
    "    elif get_score(my_action[-1], observation.lastOpponentAction) == 1:\n",
    "        answer = my_action[-1]\n",
    "        my_action.append(answer)\n",
    "    else:\n",
    "        answer = random.randrange(0, configuration.signs)\n",
    "        my_action.append(answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eEBt9y3o851",
    "outputId": "b1049100-f215-47ce-9e23-994c2bba8c47"
   },
   "outputs": [],
   "source": [
    "%%writefile throw_paper_if_win.py\n",
    "import random\n",
    "import math\n",
    "\n",
    "my_action = []\n",
    "\n",
    "def keep_strategy(observation, configuration):\n",
    "    def get_score(left_move, right_move):\n",
    "        # This method exists in this file so it can be consumed from rps.py and agents.py without a circular dependency\n",
    "        delta = (\n",
    "            right_move - left_move\n",
    "            if (left_move + right_move) % 2 == 0\n",
    "            else left_move - right_move\n",
    "        )\n",
    "        return 0 if delta == 0 else math.copysign(1, delta)\n",
    "    global my_action\n",
    "    if observation.step == 0:\n",
    "        answer = random.randrange(0, configuration.signs)\n",
    "        my_action.append(answer)\n",
    "    elif get_score(my_action[-1], observation.lastOpponentAction) == 1:\n",
    "        answer = 1\n",
    "        my_action.append(answer)\n",
    "    else:\n",
    "        answer = random.randrange(0, configuration.signs)\n",
    "        my_action.append(answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3XbfNq04cE5",
    "outputId": "ae3807cd-64fd-4189-dc38-141d15a06960"
   },
   "outputs": [],
   "source": [
    "%%writefile random_goblin.py\n",
    "import random\n",
    "\n",
    "\n",
    "def random_goblin(observation, configuration):\n",
    "    return random.randint(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BnxIuxfupCRG",
    "outputId": "3685be22-de79-4c95-abbe-a25ba8763d25"
   },
   "outputs": [],
   "source": [
    "%%writefile throw_scissors_if_lose.py\n",
    "import random\n",
    "import math\n",
    "\n",
    "my_action = []\n",
    "\n",
    "def keep_strategy(observation, configuration):\n",
    "    \"\"\"\n",
    "    Keep stategy if win\n",
    "    \"\"\"\n",
    "    def get_score(left_move, right_move):\n",
    "        # This method exists in this file so it can be consumed from rps.py and agents.py without a circular dependency\n",
    "        delta = (\n",
    "            right_move - left_move\n",
    "            if (left_move + right_move) % 2 == 0\n",
    "            else left_move - right_move\n",
    "        )\n",
    "        return 0 if delta == 0 else math.copysign(1, delta)\n",
    "    global my_action\n",
    "    if observation.step == 0:\n",
    "        answer = random.randrange(0, configuration.signs)\n",
    "        my_action.append(answer)\n",
    "    elif get_score(my_action[-1], observation.lastOpponentAction) < 1:\n",
    "        answer = 2\n",
    "        my_action.append(answer)\n",
    "    else:\n",
    "        answer = random.randrange(0, configuration.signs)\n",
    "        my_action.append(answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "VXkGJ76BX98l",
    "outputId": "63586a7c-cd21-457a-c695-4ac9c146ea28"
   },
   "outputs": [],
   "source": [
    "# Создаём среду для игры \"Камень, ножницы, бумага\"\n",
    "env = make(\"rps\",configuration={\"episodeSteps\": 1000}, debug=True)\n",
    "\n",
    "# Запускаем игру с вашим агентом против самого себя\n",
    "env.run(['random_goblin.py', 'paper'])\n",
    "\n",
    "# Отображаем результаты игры\n",
    "env.render(mode=\"ipython\", width=500, height=400)\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa9mUJS7l-VK"
   },
   "source": [
    " Основная идея заключается в том, чтобы запомнить последовательность предыдущих ходов соперника, чтобы затем на основе этой последовательности прогнозировать его следующий ход и выбрать действие, которое сможет победить предсказанный ход."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86m6l9vrs9-x",
    "outputId": "50f0c8f5-a43b-43e2-84cb-ee9b8d9f360d"
   },
   "outputs": [],
   "source": [
    "%%writefile agent7.py\n",
    "import random\n",
    "def statistical(observation, configuration):\n",
    "  ## Объявляем глобальную переменную для хранения гистограммы действий\n",
    "    global action_histogram\n",
    "    if observation.step == 0:\n",
    "      # На первом шаге инициализируем гистограмму действий\n",
    "        action_histogram = {}\n",
    "        return\n",
    "    action = observation.lastOpponentAction # Получаем последнее действие противника\n",
    "\n",
    "    #Если действие противника отсутствует в гистограмме, добавляем его\n",
    "    if action not in action_histogram:\n",
    "        action_histogram[action] = 0\n",
    "    action_histogram[action] += 1\n",
    "    mode_action = None    #Переменная для хранения наиболее частого действия\n",
    "    mode_action_count = None  # Переменная для хранения частоты этого действия\n",
    "\n",
    "\n",
    "# Итерируем по всем записям гистограммы для поиска наиболее частого действия\n",
    "    for k, v in action_histogram.items():\n",
    "        if mode_action_count is None or v > mode_action_count:\n",
    "            mode_action = k\n",
    "            mode_action_count = v\n",
    "            continue\n",
    "\n",
    "    return (mode_action + 1) % configuration.signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbkEMwyQtOAp",
    "outputId": "c8c1f59f-f565-4f86-e963-fd730b6a6e99"
   },
   "outputs": [],
   "source": [
    "%%writefile fixed_statistic.py\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "def fixed_statistic(observation, configuration):\n",
    "    \"\"\"\n",
    "    Strategy based on https://avatars.dzeninfra.ru/get-zen_doc/3985649/pub_5faa46b389ace40d9a449e91_5faa816a9c3dc81f90d0e63e/scale_1200\n",
    "    \"\"\"\n",
    "    all_results = [0]*int(configuration.episodeSteps*0.354)+[1]*int(configuration.episodeSteps*0.296) +\\\n",
    "     [2]*int(configuration.episodeSteps*0.35)\n",
    "    return random.choice(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EP6lcHjZpsh2",
    "outputId": "d7324304-2874-45ab-e653-f8e625e60fc2"
   },
   "outputs": [],
   "source": [
    "%%writefile neural_network.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Инициализация модели нейронной сети\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(6,), activation=\"relu\"),  # Входные данные — 6 последних ходов\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(3, activation=\"softmax\")  # Выход — вероятности для \"Камень\", \"Бумага\", \"Ножницы\"\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "# Инициализация памяти ходов с начальным значением\n",
    "history = [0, 0, 0, 0, 0, 0]  # Начальная последовательность, чтобы избежать ошибок при первых шагах\n",
    "\n",
    "def neural_network_agent(observation, configuration):\n",
    "    global history\n",
    "\n",
    "    # Добавляем предыдущий ход соперника и наш ход в историю\n",
    "    if observation.step > 0:\n",
    "        history.extend([observation.lastOpponentAction, history[-1]])\n",
    "\n",
    "    # Если данных недостаточно, выбираем случайный ход\n",
    "    if len(history) < 6:\n",
    "        action = int(np.random.randint(3))\n",
    "        history.append(action)\n",
    "        return action\n",
    "\n",
    "    # Формируем входные данные из последних 6 ходов\n",
    "    input_data = np.array(history[-6:]).reshape(1, -1)\n",
    "\n",
    "    # Прогнозируем следующий ход соперника\n",
    "    opponent_pred = np.argmax(model.predict(input_data)[0])\n",
    "\n",
    "    # Выбираем действие, которое побеждает предсказанный ход соперника\n",
    "    action = (opponent_pred + 1) % 3\n",
    "    history.append(action)\n",
    "\n",
    "    # Отключаем обучение в реальном времени для стабильности (опционально включить для обучения)\n",
    "    # target = np.zeros(3)\n",
    "    # target[observation.lastOpponentAction] = 1\n",
    "    # model.fit(input_data, target.reshape(1, -1), epochs=1, verbose=0)\n",
    "\n",
    "    return int(action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLqIX4F2lmyO",
    "outputId": "fe1f032b-03e6-4cc4-abed-f2a6b564f67e"
   },
   "outputs": [],
   "source": [
    "%%writefile markov.py\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "def markov_agent(observation, configuration):\n",
    "    k = 2\n",
    "    global table, action_seq\n",
    "    if observation.step % 250 == 0: # refresh table every 250 steps\n",
    "        action_seq, table = [], collections.defaultdict(lambda: [1, 1, 1])\n",
    "    if len(action_seq) <= 2 * k + 1:\n",
    "        action = int(np.random.randint(3))\n",
    "        if observation.step > 0:\n",
    "            action_seq.extend([observation.lastOpponentAction, action])\n",
    "        else:\n",
    "            action_seq.append(action)\n",
    "        return action\n",
    "    # update table\n",
    "    key = ''.join([str(a) for a in action_seq[:-1]])\n",
    "    table[key][observation.lastOpponentAction] += 1\n",
    "    # update action seq\n",
    "    action_seq[:-2] = action_seq[2:]\n",
    "    action_seq[-2] = observation.lastOpponentAction\n",
    "    # predict opponent next move\n",
    "    key = ''.join([str(a) for a in action_seq[:-1]])\n",
    "    if observation.step < 500:\n",
    "        next_opponent_action_pred = np.argmax(table[key])\n",
    "    else:\n",
    "        scores = np.array(table[key])\n",
    "        next_opponent_action_pred = np.random.choice(3, p=scores/scores.sum()) # add stochasticity for second part of the game\n",
    "    # make an action\n",
    "    action = (next_opponent_action_pred + 1) % 3\n",
    "    # if high probability to lose -> let's surprise our opponent with sudden change of our strategy\n",
    "    if observation.step > 900:\n",
    "        action = next_opponent_action_pred\n",
    "    action_seq[-1] = action\n",
    "    return int(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmfSRIrSnGzK",
    "outputId": "1a7aed9d-c96a-4dc9-89ef-0d1c71ce27a1"
   },
   "outputs": [],
   "source": [
    "%%writefile decision_tree.py\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def construct_local_features(rollouts):\n",
    "    step_mode_features = np.array([[step % k for step in rollouts['steps']] for k in (2, 3, 5)])\n",
    "    step_div_features = np.array([[step // k for step in rollouts['steps']] for k in (100, 150, 250)])\n",
    "    features = np.concatenate([step_mode_features, step_div_features])\n",
    "    features = np.append(features, rollouts['actions'])\n",
    "    features = np.append(features, rollouts['opp-actions'])\n",
    "    return features\n",
    "\n",
    "def construct_global_features(rollouts):\n",
    "    features = []\n",
    "    for key in ['actions', 'opp-actions']:\n",
    "        for i in range(3):\n",
    "            actions_count = np.mean([r == i for r in rollouts[key]])\n",
    "            features.append(actions_count)\n",
    "    return np.array(features)\n",
    "\n",
    "def construct_features(short_stat_rollouts, long_stat_rollouts):\n",
    "    lf = construct_local_features(short_stat_rollouts)\n",
    "    gf = construct_global_features(long_stat_rollouts)\n",
    "    features = np.concatenate([lf, gf])\n",
    "    return features\n",
    "\n",
    "def predict_opponent_move(train_data, test_sample):\n",
    "    classifier = DecisionTreeClassifier(random_state=42)\n",
    "    classifier.fit(train_data['x'], train_data['y'])\n",
    "    return classifier.predict(test_sample)\n",
    "\n",
    "def update_rollouts_hist(rollouts_hist, last_move, opp_last_action):\n",
    "    rollouts_hist['steps'].append(last_move['step'])\n",
    "    rollouts_hist['actions'].append(last_move['action'])\n",
    "    rollouts_hist['opp-actions'].append(opp_last_action)\n",
    "    return rollouts_hist\n",
    "\n",
    "def warmup_strategy(observation, configuration):\n",
    "    global rollouts_hist, last_move\n",
    "    action = int(np.random.randint(3))\n",
    "    if observation.step == 0:\n",
    "        last_move = {'step': 0, 'action': action}\n",
    "        rollouts_hist = {'steps': [], 'actions': [], 'opp-actions': []}\n",
    "    else:\n",
    "        rollouts_hist = update_rollouts_hist(rollouts_hist, last_move, observation.lastOpponentAction)\n",
    "        last_move = {'step': observation.step, 'action': action}\n",
    "    return int(action)\n",
    "\n",
    "def init_training_data(rollouts_hist, k):\n",
    "    for i in range(len(rollouts_hist['steps']) - k + 1):\n",
    "        short_stat_rollouts = {key: rollouts_hist[key][i:i+k] for key in rollouts_hist}\n",
    "        long_stat_rollouts = {key: rollouts_hist[key][:i+k] for key in rollouts_hist}\n",
    "        features = construct_features(short_stat_rollouts, long_stat_rollouts)\n",
    "        data['x'].append(features)\n",
    "    test_sample = data['x'][-1].reshape(1, -1)\n",
    "    data['x'] = data['x'][:-1]\n",
    "    data['y'] = rollouts_hist['opp-actions'][k:]\n",
    "    return data, test_sample\n",
    "\n",
    "def agent(observation, configuration):\n",
    "    # hyperparameters\n",
    "    k = 5\n",
    "    min_samples = 25\n",
    "    global rollouts_hist, last_move, data, test_sample\n",
    "    if observation.step == 0:\n",
    "        data = {'x': [], 'y': []}\n",
    "    # if not enough data -> randomize\n",
    "    if observation.step <= min_samples + k:\n",
    "        return warmup_strategy(observation, configuration)\n",
    "    # update statistics\n",
    "    rollouts_hist = update_rollouts_hist(rollouts_hist, last_move, observation.lastOpponentAction)\n",
    "    # update training data\n",
    "    if len(data['x']) == 0:\n",
    "        data, test_sample = init_training_data(rollouts_hist, k)\n",
    "    else:\n",
    "        short_stat_rollouts = {key: rollouts_hist[key][-k:] for key in rollouts_hist}\n",
    "        features = construct_features(short_stat_rollouts, rollouts_hist)\n",
    "        data['x'].append(test_sample[0])\n",
    "        data['y'] = rollouts_hist['opp-actions'][k:]\n",
    "        test_sample = features.reshape(1, -1)\n",
    "\n",
    "    # predict opponents move and choose an action\n",
    "    next_opp_action_pred = predict_opponent_move(data, test_sample)\n",
    "    action = int((next_opp_action_pred + 1) % 3)\n",
    "    last_move = {'step': observation.step, 'action': action}\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSx84lnRne5u",
    "outputId": "0c361d63-eaeb-4657-8ac3-65badc6f6747"
   },
   "outputs": [],
   "source": [
    "%%writefile geometry.py\n",
    "import operator\n",
    "import numpy as np\n",
    "import cmath\n",
    "from typing import List\n",
    "from collections import namedtuple\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "\n",
    "basis = np.array(\n",
    "    [1, cmath.exp(2j * cmath.pi * 1 / 3), cmath.exp(2j * cmath.pi * 2 / 3)]\n",
    ")\n",
    "\n",
    "\n",
    "HistMatchResult = namedtuple(\"HistMatchResult\", \"idx length\")\n",
    "\n",
    "\n",
    "def find_all_longest(seq, max_len=None) -> List[HistMatchResult]:\n",
    "    \"\"\"\n",
    "    Find all indices where end of `seq` matches some past.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    i_search_start = len(seq) - 2\n",
    "\n",
    "    while i_search_start > 0:\n",
    "        i_sub = -1\n",
    "        i_search = i_search_start\n",
    "        length = 0\n",
    "\n",
    "        while i_search >= 0 and seq[i_sub] == seq[i_search]:\n",
    "            length += 1\n",
    "            i_sub -= 1\n",
    "            i_search -= 1\n",
    "\n",
    "            if max_len is not None and length > max_len:\n",
    "                break\n",
    "\n",
    "        if length > 0:\n",
    "            result.append(HistMatchResult(i_search_start + 1, length))\n",
    "\n",
    "        i_search_start -= 1\n",
    "\n",
    "    result = sorted(result, key=operator.attrgetter(\"length\"), reverse=True)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def probs_to_complex(p):\n",
    "    return p @ basis\n",
    "\n",
    "\n",
    "def _fix_probs(probs):\n",
    "    \"\"\"\n",
    "    Put probs back into triangle. Sometimes this happens due to rounding errors or if you\n",
    "    use complex numbers which are outside the triangle.\n",
    "    \"\"\"\n",
    "    if min(probs) < 0:\n",
    "        probs -= min(probs)\n",
    "\n",
    "    probs /= sum(probs)\n",
    "\n",
    "    return probs\n",
    "\n",
    "\n",
    "def complex_to_probs(z):\n",
    "    probs = (2 * (z * basis.conjugate()).real + 1) / 3\n",
    "    probs = _fix_probs(probs)\n",
    "    return probs\n",
    "\n",
    "\n",
    "def z_from_action(action):\n",
    "    return basis[action]\n",
    "\n",
    "\n",
    "def sample_from_z(z):\n",
    "    probs = complex_to_probs(z)\n",
    "    return np.random.choice(3, p=probs)\n",
    "\n",
    "\n",
    "def bound(z):\n",
    "    return probs_to_complex(complex_to_probs(z))\n",
    "\n",
    "\n",
    "def norm(z):\n",
    "    return bound(z / abs(z))\n",
    "\n",
    "\n",
    "class Pred:\n",
    "    def __init__(self, *, alpha):\n",
    "        self.offset = 0\n",
    "        self.alpha = alpha\n",
    "        self.last_feat = None\n",
    "\n",
    "    def train(self, target):\n",
    "        if self.last_feat is not None:\n",
    "            offset = target * self.last_feat.conjugate()   # fixed\n",
    "\n",
    "            self.offset = (1 - self.alpha) * self.offset + self.alpha * offset\n",
    "\n",
    "    def predict(self, feat):\n",
    "        \"\"\"\n",
    "        feat is an arbitrary feature with a probability on 0,1,2\n",
    "        anything which could be useful anchor to start with some kind of sensible direction\n",
    "        \"\"\"\n",
    "        feat = norm(feat)\n",
    "\n",
    "        # offset = mean(target - feat)\n",
    "        # so here we see something like: result = feat + mean(target - feat)\n",
    "        # which seems natural and accounts for the correlation between target and feat\n",
    "        # all RPSContest bots do no more than that as their first step, just in a different way\n",
    "\n",
    "        result = feat * self.offset\n",
    "\n",
    "        self.last_feat = feat\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "class BaseAgent:\n",
    "    def __init__(self):\n",
    "        self.my_hist = []\n",
    "        self.opp_hist = []\n",
    "        self.my_opp_hist = []\n",
    "        self.outcome_hist = []\n",
    "        self.step = None\n",
    "\n",
    "    def __call__(self, obs, conf):\n",
    "        try:\n",
    "            if obs.step == 0:\n",
    "                action = np.random.choice(3)\n",
    "                self.my_hist.append(action)\n",
    "                return action\n",
    "\n",
    "            self.step = obs.step\n",
    "\n",
    "            opp = int(obs.lastOpponentAction)\n",
    "            my = self.my_hist[-1]\n",
    "\n",
    "            self.my_opp_hist.append((my, opp))\n",
    "            self.opp_hist.append(opp)\n",
    "\n",
    "            outcome = {0: 0, 1: 1, 2: -1}[(my - opp) % 3]\n",
    "            self.outcome_hist.append(outcome)\n",
    "\n",
    "            action = self.action()\n",
    "\n",
    "            self.my_hist.append(action)\n",
    "\n",
    "            return action\n",
    "        except Exception:\n",
    "            traceback.print_exc(file=sys.stderr)\n",
    "            raise\n",
    "\n",
    "    def action(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Agent(BaseAgent):\n",
    "    def __init__(self, alpha=0.01):\n",
    "        super().__init__()\n",
    "\n",
    "        self.predictor = Pred(alpha=alpha)\n",
    "\n",
    "    def action(self):\n",
    "        self.train()\n",
    "\n",
    "        pred = self.preds()\n",
    "\n",
    "        return_action = sample_from_z(pred)\n",
    "\n",
    "        return return_action\n",
    "\n",
    "    def train(self):\n",
    "        last_beat_opp = z_from_action((self.opp_hist[-1] + 1) % 3)\n",
    "        self.predictor.train(last_beat_opp)\n",
    "\n",
    "    def preds(self):\n",
    "        hist_match = find_all_longest(self.my_opp_hist, max_len=20)\n",
    "\n",
    "        if not hist_match:\n",
    "             return 0\n",
    "\n",
    "        feat = z_from_action(self.opp_hist[hist_match[0].idx])\n",
    "\n",
    "        pred = self.predictor.predict(feat)\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "def call_agent(obs, conf):\n",
    "    return agent(obs, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMhT3rHJfUNK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "agents = [file for file in os.listdir() if file.endswith('.py')]\n",
    "agents\n",
    "dict_win = {agent: [0, 0, 0] for agent in agents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzahC3b8iF8X",
    "outputId": "49278c1c-f24f-47dd-e25d-8732e533322e"
   },
   "outputs": [],
   "source": [
    "np.rps = []\n",
    "for i in range(len(agents)):\n",
    "  np.rps_row = []\n",
    "  a = 0\n",
    "  for j in range(len(agents)):\n",
    "    one_set = []\n",
    "    one_set = evaluate(\n",
    "                        \"rps\", #environment to use - no need to change\n",
    "                        [agents[i], agents[j]], #agents to evaluate\n",
    "                        configuration={\"episodeSteps\": 70, 'tieRewardThreshold': 1} #number of episodes\n",
    "                      )\n",
    "    print(agents[i], agents[j])\n",
    "    np.rps_row += one_set\n",
    "    print(one_set)\n",
    "    if one_set[0][0] > one_set[0][1]:\n",
    "      dict_win[agents[i]][0] += 1\n",
    "    elif one_set[0][0] < one_set[0][1]:\n",
    "      dict_win[agents[i]][1] += 1\n",
    "    else:\n",
    "      dict_win[agents[i]][2] += 1\n",
    "\n",
    "  np.rps.append(np.rps_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "QpSEvbjJiF42",
    "outputId": "d5c2122a-74dc-4d30-f3f1-cf0f5de00687"
   },
   "outputs": [],
   "source": [
    "colName = [\"Побед\", \"Поражний\", \"Ничьих\"]\n",
    "df = pd.DataFrame.from_dict(dict_win, orient='index', columns=colName)\n",
    "df = df.sort_values(\"Побед\",ascending = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "_r4ueK11iF07",
    "outputId": "1295f3ea-4914-4938-ccb3-95addc621ee7"
   },
   "outputs": [],
   "source": [
    "from operator import index\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Hide axes\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "# Table from Ed Smith answer\n",
    "clust_data = np.rps\n",
    "collabel=(agents)\n",
    "rowlabel=(agents)\n",
    "\n",
    "the_table = ax.table(cellText=clust_data,colLabels=collabel, rowLabels=rowlabel, loc='center')\n",
    "the_table.auto_set_font_size(False)\n",
    "the_table.set_fontsize(5)\n",
    "plt.figure(figsize=(40, 40))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "JMXb0O1KiFsW",
    "outputId": "906fee4f-9336-4704-e399-a85f197e19ea"
   },
   "outputs": [],
   "source": [
    "df1 = df\n",
    "for i in df1.index:\n",
    "    df1[\"Агент\"] = df1.index\n",
    "\n",
    "sns.barplot(\n",
    "    x='Побед',\n",
    "    y=df1.index,\n",
    "    #hue=\"Побед\",\n",
    "    ci=90,\n",
    "    color='Red',\n",
    "    saturation=1,\n",
    "    dodge= False,\n",
    "    data=df1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "7dUSJ0eJdYdu",
    "outputId": "fb94add6-0dd9-4cd9-8529-6c7a3b859a7c"
   },
   "outputs": [],
   "source": [
    "\n",
    "df1.plot.barh(stacked=True, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKdpvRttl0zs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
